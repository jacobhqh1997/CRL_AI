{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "- This juypter notebook is to perform example for  SETD Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from monai.apps import download_url, download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.losses import BendingEnergyLoss, MultiScaleLoss, DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.nets import LocalNet\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandAffined,\n",
    "    Resized,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    RandRotated,\n",
    ")\n",
    "from monai.utils import set_determinism, first\n",
    "import glob\n",
    "import torch\n",
    "from resnet50 import generate_model\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50_GRU_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.2, seq_len=128, pretrain_path='./path/to/resnet_50_23dataset.pth'):\n",
    "        super(ResNet50_GRU_Model, self).__init__()\n",
    "        self.resnet50model = generate_model(input_W=96, input_H=96, input_D=14, pretrain_path=pretrain_path, pretrained=True)\n",
    "        for name, param in self.resnet50model.named_parameters():\n",
    "            if 'conv_seg' not in name and 'reduce_channels' not in name and 'reduce_bn' not in name and 'reduce_relu' not in name:\n",
    "                param.requires_grad = False\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.seq_len = seq_len\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, image2, image3):\n",
    "        ddf2 = self.resnet50model(image2)\n",
    "        ddf3 = self.resnet50model(image3)\n",
    "        encoder_concatenated = torch.cat([ddf2.squeeze(-3).squeeze(-2).squeeze(-1), ddf3.squeeze(-3).squeeze(-2).squeeze(-1)], dim=1)\n",
    "        output, _ = self.gru(encoder_concatenated.unsqueeze(1).repeat(1, self.seq_len, 1))\n",
    "        output = output[:, -1, :]\n",
    "        output = self.bn(output)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "def maskcroppingbox(data, mask, use2D=False):\n",
    "    mask_2 = np.argwhere(mask)\n",
    "    (zstart, ystart, xstart), (zstop, ystop, xstop) = mask_2.min(axis=0)-1, mask_2.max(axis=0) + 1\n",
    "    zstart = max(0, zstart)\n",
    "    ystart =max(0, ystart)\n",
    "    xstart = max(0, xstart)\n",
    "    zstop = min(data.shape[0], zstop)\n",
    "    ystop = min(data.shape[1], ystop)\n",
    "    xstop = min(data.shape[2], xstop)\n",
    "    roi_image = data[zstart:zstop, ystart:ystop, xstart:xstop]\n",
    "    roi_mask = mask[zstart:zstop, ystart:ystop, xstart:xstop]\n",
    "    roi_image[roi_mask < 1] = 0\n",
    "    return roi_image\n",
    "\n",
    "artirial_imgpath = './path/to/3T_artirialorg.nii.gz'\n",
    "nephrogenic_imgpath = './path/to/3T_nephrogenicorg.nii.gz'\n",
    "artirial_maskpath = './path/to/3T_artirialseg.nii.gz'\n",
    "nephrogenic_maskpath = './path/to/3T_nephrogenicseg.nii.gz'\n",
    "artirial_img = sitk.ReadImage(artirial_imgpath)\n",
    "artirial_img = sitk.GetArrayFromImage(artirial_img)\n",
    "artirial_mask = sitk.ReadImage(artirial_maskpath)\n",
    "artirial_mask = sitk.GetArrayFromImage(artirial_mask)\n",
    "nephrogenic_img = sitk.ReadImage(nephrogenic_imgpath)\n",
    "nephrogenic_img = sitk.GetArrayFromImage(nephrogenic_img)\n",
    "nephrogenic_mask = sitk.ReadImage(nephrogenic_maskpath)\n",
    "nephrogenic_mask = sitk.GetArrayFromImage(nephrogenic_mask)\n",
    "artirial_croppedimg = maskcroppingbox(artirial_img, artirial_mask)\n",
    "nephrogenic_croppedimg = maskcroppingbox(nephrogenic_img, nephrogenic_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./path/to/artirial_croppedimg.npy\", artirial_croppedimg)\n",
    "np.save(\"./path/to/nephrogenic_croppedimg.npy\", nephrogenic_croppedimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artirial_croppedimg_path = './path/to/unenhanced_croppedimg.npy'  # Provide the file path or PathLike object for the artirial cropped image\n",
    "nephrogenic_croppedimg_path = './path/to/unenhanced_croppedimg.npy'  # Provide the file path or PathLike object for the nephrogenic cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_external_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image2\", \"image3\"], ensure_channel_first=True),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image2\", \"image3\"],\n",
    "            a_min=0,\n",
    "            a_max=250,\n",
    "            b_min=0,\n",
    "            b_max=250,\n",
    "            clip=True,\n",
    "        ),\n",
    "        Resized(\n",
    "            keys=[\"image2\", \"image3\"],\n",
    "            mode=\"trilinear\",\n",
    "            align_corners=True,\n",
    "            spatial_size=(96, 96, 14),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "input_data = {\n",
    "    \"image2\": artirial_croppedimg_path,\n",
    "    \"image3\": nephrogenic_croppedimg_path,\n",
    "}\n",
    "input_data = val_external_transforms(input_data)\n",
    "image2 = torch.from_numpy(np.array(input_data[\"image2\"])).to(device)\n",
    "image3 = torch.from_numpy(np.array(input_data[\"image3\"])).to(device)\n",
    "image2 = image2.unsqueeze(0)\n",
    "image3 = image3.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = ResNet50_GRU_Model(input_size=256, hidden_size=128, output_size=2).to(device)\n",
    "model_path = \"./path/to/best_metric_model_classification3d_array.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image2, image3)\n",
    "    output_list = output.argmax(dim=1).cpu().numpy().tolist()\n",
    "    proba = torch.nn.functional.softmax(output, dim=1).detach().cpu().numpy().tolist()\n",
    "print(output_list)\n",
    "print(proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
