{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, os\n",
    "import glob\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "import torch\n",
    "import torchio as tio\n",
    "from monai.transforms import (\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    SaveImaged,\n",
    "    Invertd,\n",
    ")\n",
    "from models.networks import P_RNet3D\n",
    "from monai.inferers import sliding_window_inference\n",
    "from geodis_toolkits  import get_geodismaps\n",
    "from models.networks import P_RNet3D\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pnet_best_ckpt_dir = \"./path/to/best_pnet_init_train\"\n",
    "pnet_best_ckpt_path = sorted(glob.glob(f\"{pnet_best_ckpt_dir}/*.pt\"))[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnet_inference(\n",
    "    image_path,\n",
    "    save_path,\n",
    "    pnet, \n",
    "    transform, \n",
    "    device\n",
    "):\n",
    "    \"\"\"\n",
    "    P-Net inference function\n",
    "    \n",
    "    Args:\n",
    "        image_path:     file path of input image (ex. image_path.nii.gz)\n",
    "        save_path:      file path to save result (ex. pnet_pred.nii.gz)\n",
    "        pnet:           trained pnet model (torch.nn.Module)\n",
    "        transform:      preprocessing transforms (torchio.Compose)\n",
    "        norm_transform: preprocessing transforms (normalization)\n",
    "        device:         torch device (torch.device)\n",
    "    \"\"\"\n",
    "    test_images =sorted(glob.glob(os.path.join(image_path, \"imagesTr\", \"*.nii.gz\")))\n",
    "    test_data = [{\"image\": image} for image in test_images]\n",
    "    test_org_ds = Dataset(data=test_data, transform=transform)\n",
    "    test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=1)\n",
    "    post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=transform,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=save_path, squeeze_end_dims=True,output_postfix=\"pnet\",resample=False,separate_folder=False)\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_org_loader:\n",
    "            test_inputs = test_data[\"image\"].to(device)\n",
    "            test_data[\"pred\"] = pnet(test_inputs) \n",
    "            test_data = [post_transforms(i) for i in decollate_batch(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders.transforms import get_transform\n",
    "pnet = P_RNet3D(1,32,2,True).to(device)\n",
    "pnet.load_state_dict(torch.load(pnet_best_ckpt_path))\n",
    "pnet.eval()\n",
    "test_images = \"path/to/dataset/\"\n",
    "test_transform = get_transform(\"post\")\n",
    "save_path_pnet = \"./save_path\" \n",
    "pnet_inference(image_path=test_images,\n",
    "            save_path=save_path_pnet,\n",
    "            pnet=pnet,\n",
    "            transform=test_transform,\n",
    "            device=device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transform = tio.ZNormalization(masking_method=lambda x: x > 0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "rnet_best_ckpt_dir = \"./path/to/best_rnet_init_train\"\n",
    "rnet_best_ckpt_path = sorted(glob.glob(f\"{rnet_best_ckpt_dir}/*.pt\"))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnet_inference(\n",
    "    image_path,\n",
    "    save_path,\n",
    "    rnet, \n",
    "    transform, \n",
    "    norm_transform,\n",
    "    device\n",
    "):\n",
    "    \"\"\"\n",
    "    P-Net inference function\n",
    "    \n",
    "    Args:\n",
    "        image_path:     file path of input image (ex. image_path.nii.gz)\n",
    "        save_path:      file path to save result (ex. pnet_pred.nii.gz)\n",
    "        pnet:           trained pnet model (torch.nn.Module)\n",
    "        transform:      preprocessing transforms (torchio.Compose)\n",
    "        norm_transform: preprocessing transforms (normalization)\n",
    "        device:         torch device (torch.device)\n",
    "    \"\"\"\n",
    "    test_images =sorted(glob.glob(os.path.join(image_path, \"imagesTr\", \"*.nii.gz\")))\n",
    "    test_labels = sorted(glob.glob(os.path.join(image_path, \"labelsTr\", \"*.nii.gz\")))\n",
    "    pnet_masks = sorted(glob.glob(os.path.join(image_path, \"pnet_masks\", \"*.nii.gz\")))\n",
    "    test_data = [{\"image\": image, \"P_mask\": mask_name,\"label\": label_name} for image, mask_name, label_name in zip(test_images,pnet_masks,test_labels)]\n",
    "    test_org_ds = Dataset(data=test_data, transform=transform)\n",
    "    test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=1)\n",
    "    post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=transform,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=save_path, squeeze_end_dims=True,output_postfix=\"rnet\",resample=False,separate_folder=False)\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_org_loader:\n",
    "            test_inputs = test_data[\"image\"].to(device)\n",
    "            true_labels = test_data[\"label\"].to(device).type(torch.long)\n",
    "            pnet_pred_labels = test_data[\"P_mask\"].to(device).type(torch.long)\n",
    "            fore_dist_map, back_dist_map = get_geodismaps(test_inputs.to(\"cpu\").numpy(), \n",
    "                                                            true_labels.squeeze(dim=1).to(\"cpu\").numpy(), \n",
    "                                                            pnet_pred_labels.squeeze(dim=1).to(\"cpu\").numpy()) \n",
    "            fore_dist_map = norm_transform(torch.Tensor(fore_dist_map).squeeze(dim=1)) \n",
    "            back_dist_map = norm_transform(torch.Tensor(back_dist_map).squeeze(dim=1))\n",
    "            fore_dist_map = fore_dist_map.unsqueeze(dim=1)\n",
    "            back_dist_map = back_dist_map.unsqueeze(dim=1)\n",
    "            rnet_inputs = torch.cat([\n",
    "                test_inputs,\n",
    "                pnet_pred_labels, \n",
    "                fore_dist_map.to(device), \n",
    "                back_dist_map.to(device)\n",
    "            ], dim=1)            \n",
    "            roi_size = (96, 96, 96)\n",
    "            sw_batch_size = 2\n",
    "            test_data[\"pred\"] = sliding_window_inference(rnet_inputs, roi_size, sw_batch_size, rnet,overlap=0.6)\n",
    "            test_data = [post_transforms(i) for i in decollate_batch(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders.transforms_r import get_transform\n",
    "rnet = P_RNet3D(4,32,2,True).to(device)\n",
    "rnet.load_state_dict(torch.load(rnet_best_ckpt_path))\n",
    "rnet.eval()\n",
    "test_images = \"path/to/dataset/\"\n",
    "test_transform = get_transform(\"post\")\n",
    "save_path_rnet = \"path/to/save_path_rnet\" \n",
    "rnet_inference(image_path=test_images,\n",
    "            save_path=save_path_rnet,\n",
    "            rnet=rnet,\n",
    "            transform=test_transform,\n",
    "            norm_transform= norm_transform,\n",
    "            device=device)   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06b312d4da2a9a3686a6d52820f5105a519faf7cd6cc067e3b3e5e11d5973e41"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ys_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
